{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ChestXray_CCN_bbXXXXXXXX.ipynb","version":"0.3.2","provenance":[{"file_id":"1qglZxbhepBt2_UU43RGhCD9uxvNe2O_D","timestamp":1565714684553},{"file_id":"1nGVik4ep9DGfek8cO3j8ldnK00o8Yb0Q","timestamp":1565681653417},{"file_id":"1vI9I3777CrVARdb00aAwmy-Fcl9N2MEI","timestamp":1565345376384},{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise4-Answer.ipynb","timestamp":1560253995283}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TdZPsFbZ3S5M","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras import Sequential\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import logging\n","logging.getLogger('tensorflow').disabled = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWfDIH7iLCnf","colab_type":"code","colab":{}},"source":["if tf.test.is_gpu_available():\n","    print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n","    !/usr/bin/nvidia-smi -L"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJXC48mKLIwS","colab_type":"text"},"source":["#Part I: Design Your Own CNN"]},{"cell_type":"markdown","metadata":{"id":"DMrsQJe5MKp9","colab_type":"text"},"source":["##Data preparation\n","###Data download and unzip"]},{"cell_type":"code","metadata":{"id":"HFEsDVhnLmIX","colab_type":"code","colab":{}},"source":["!wget --no-check-certificate --show-progress -q\\\n","    \"https://www.dropbox.com/s/y0q7lt3mq436es1/chest_xray_150x150.zip?dl=0\" \\\n","    -O \"/tmp/chest_xray_150x150.zip\"\n","\n","import zipfile\n","import os\n","zip_ref = zipfile.ZipFile(\"/tmp/chest_xray_150x150.zip\", 'r')\n","zip_ref.extractall(\"/tmp\")\n","zip_ref.close()\n","\n","root_dir = \"/tmp/chest_xray_150x150\"\n","\n","class_names = os.listdir(root_dir + \"/train\")\n","\n","train, test, val = {}, {}, {}\n","train_files, test_files, val_files = {}, {}, {}\n","for class_name in class_names:\n","    train_files[class_name] = os.listdir(root_dir + \"/train/\" + class_name)\n","    test_files[class_name] = os.listdir(root_dir + \"/test/\" + class_name)\n","    val_files[class_name] = os.listdir(root_dir + \"/val/\" + class_name)\n","print(\"#training data: %s\" % ([(k,len(v)) for (k,v) in train_files.items()]))\n","print(\"#test data: %s\" % ([(k,len(v)) for (k,v) in test_files.items()]))\n","print(\"#val data: %s\" % ([(k,len(v)) for (k,v) in val_files.items()]))\n","\n","train['files'], test['files'], val['files'] = train_files, test_files, val_files"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3BECaQcQMfd6","colab_type":"text"},"source":["##Setting image generators for data augmentation"]},{"cell_type":"code","metadata":{"id":"5ZnEulyB3Jc5","colab_type":"code","colab":{}},"source":["preprocess_input = lambda x: x/127.5-1.  #!!! keep unchanged\n","\n","#!!! You may modify the ImageDataGenerator options for train['gen'].\n","train['gen'] = ImageDataGenerator(\n","    preprocessing_function=preprocess_input,  #!!! keep unchanged\n","    rotation_range=1,\n","    width_shift_range=0.,\n","    height_shift_range=0.,\n","    horizontal_flip=False)\n","\n","test['gen'] = ImageDataGenerator(preprocessing_function=preprocess_input)\n","val['gen'] = ImageDataGenerator(preprocessing_function=preprocess_input)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0CcNdCu3ajq","colab_type":"code","colab":{}},"source":["train['dir'] = root_dir + \"/train\"\n","test['dir'] = root_dir + \"/test\"\n","val['dir'] = root_dir + \"/val\"\n","\n","target_size = (150, 150)\n","batch_size = 64\n","\n","train['flow'] = train['gen'].flow_from_directory(train['dir'],\n","                                    class_mode=\"binary\",\n","                                    target_size=target_size,\n","                                    batch_size=batch_size)\n","\n","cid_to_class_name = {train['flow'].class_indices[name]: name for name in class_names}\n","# compute class_weight for the imbalanced training dataset\n","num_data = {k: len(v) for (k,v) in train['files'].items()}\n","max_num_data = max(num_data.values())\n","class_weight = {train['flow'].class_indices[name]: max_num_data/num_data[name] for name in class_names}\n","\n","test['flow'] = test['gen'].flow_from_directory(test['dir'],\n","                                   class_mode=\"binary\",\n","                                   target_size=target_size)\n","\n","val['flow'] = val['gen'].flow_from_directory(val['dir'],\n","                                  class_mode=\"binary\",\n","                                  target_size=target_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNkTYAmbM8rM","colab_type":"code","colab":{}},"source":["# Show some images from the generator\n","def plotImages(img_arr, lbl_arr):\n","    fig, axes = plt.subplots(1, min(len(img_arr), 5), figsize=(20,20))\n","    axes = axes.flatten()\n","    for img, lbl, ax in zip( img_arr, lbl_arr, axes):\n","        ax.imshow(img[:,:,0], cmap='gray', vmin=-1, vmax=1)\n","        ax.title.set_text(cid_to_class_name[lbl])\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","    \n","image_batch, label_batch = next(train['flow'])\n","plotImages(image_batch, label_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s__gFleQNH_Q","colab_type":"text"},"source":["##!!! Here you define a CNN model !!!"]},{"cell_type":"code","metadata":{"id":"eUcNTpra1FK0","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Sequential([\n","    #!!! Hint:\n","    #!!! Set input_shape=(target_size[0], target_size[1], 3)\n","    #!!! Use tf.keras.layers.XXXX\n","    #!!! The output layer must have 2 units with activation='softmax'\n","])\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9hfHd7T_WxC","colab_type":"code","colab":{}},"source":["#!!! You may use any callback function.\n","\n","DESIRED_TRAIN_ACCURACY = 0.99\n","DESIRED_VAL_ACCURACY = 0.85\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if(logs.get('acc')>DESIRED_TRAIN_ACCURACY and logs.get('val_acc')>DESIRED_VAL_ACCURACY):\n","            print(\"\\nReached %.0f accuracy and %.0f val accuracy.\" % (DESIRED_TRAIN_ACCURACY*100, DESIRED_VAL_ACCURACY*100))\n","            self.model.stop_training = True\n","\n","callbacks = myCallback()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pLyqXFrT6XJ","colab_type":"code","colab":{}},"source":["#!!! You may use any optimizer.\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',  # You must use this loss. \n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zwR9fXTbWIRa","colab_type":"text"},"source":["###Are you ready to execute training?  Go!"]},{"cell_type":"code","metadata":{"id":"0imravDn0Ajz","colab_type":"code","colab":{}},"source":["#!!! You may modity the options (epochs, callbacks, etc.) of fit_generator.\n","history = model.fit_generator(train['flow'], epochs=16, #class_weight=class_weight,\n","                              validation_data=val['flow'], callbacks=[callbacks])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHuO1RgGWxaT","colab_type":"text"},"source":["### Show training curve (optional)"]},{"cell_type":"code","metadata":{"id":"IdaHXD4k8Mqb","colab_type":"code","colab":{}},"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(len(loss))\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RiuJMHEuW7fY","colab_type":"text"},"source":["## Evaluation of the prediction performance"]},{"cell_type":"code","metadata":{"id":"uUOExHIS8QtD","colab_type":"code","colab":{}},"source":["score = model.evaluate(test['flow'])\n","print('Test Loss: {:3f}, Test Accuracy: {:.2f}'.format(score[0], score[1]))\n","num_test = {k: len(v) for (k,v) in test['files'].items()}\n","print(\"Chance rate of PNEUMONIA: %.2f\" % (num_test['PNEUMONIA']/sum(num_test.values())))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJ0RqA4Y8VTf","colab_type":"text"},"source":["### Demonstrate predictions"]},{"cell_type":"code","metadata":{"id":"i4QPPU9dawKL","colab_type":"code","colab":{}},"source":["#!!! Choose the dataset and class_name ####\n","dataset = test  # train, val, test\n","class_name = 'NORMAL'\n","#class_name = 'PNEUMONIA'\n","##################################\n","\n","from time import time\n","rng = np.random.RandomState(int(time()))\n","ids = rng.choice(len(dataset['files'][class_name]), 20, replace=False)\n","\n","print(\"Model predictions (blue: correct, red: incorrect)\")\n","fig, axes = plt.subplots(4,5, figsize=(10,10))\n","axes = axes.flatten()\n","for data_id, ax in zip(ids, axes):\n","    gt_class_name = class_name\n","    file = dataset['files'][gt_class_name][data_id]\n","    img_in = load_img(dataset['dir'] + '/' + gt_class_name + '/' + file, target_size=target_size)\n","    x = preprocess_input(np.expand_dims(img_to_array(img_in), axis=0))\n","    pred = model.predict(x)\n","    cid_pred = np.argmax(pred[0])\n","    pred_class_name = cid_to_class_name[cid_pred]\n","\n","    ax.imshow(img_in, cmap='gray', vmin=-1, vmax=1)\n","    ax.axis('off')\n","    ax.set_title(pred_class_name + '\\n[%.2f, %.2f]' % (pred[0][0], pred[0][1]), color='blue' if pred_class_name == gt_class_name else 'red')\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_1CClhSWbZlH","colab_type":"text"},"source":["### Visualize feature maps"]},{"cell_type":"code","metadata":{"id":"lldQdEvBlRT6","colab_type":"code","colab":{}},"source":["#!!! Choose the dataset and class_name ####\n","dataset = test  # train, val, test\n","class_name = 'NORMAL'\n","#class_name = 'PNEUMONIA'\n","##################################\n","\n","gt_class_name = class_name\n","\n","import numpy as np\n","import random\n","\n","print(\"Visualizing all feature maps for an image of the class %s in training dataset\" % (class_name))\n","successive_outputs = [layer.output for layer in model.layers[1:]]\n","visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n","\n","file = random.choice(dataset['files'][class_name])\n","img_in = load_img(dataset['dir'] + '/' + gt_class_name + '/' + file, target_size=target_size)\n","x = preprocess_input(np.expand_dims(img_to_array(img_in), axis=0))\n","successive_feature_maps = visualization_model.predict(x)\n","layer_names = [layer.name for layer in model.layers]\n","for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n","    if len(feature_map.shape) == 4:\n","        n_features = feature_map.shape[-1]\n","        size = feature_map.shape[1]\n","        display_grid = np.zeros((size, size * n_features))\n","        maps_min = feature_map[0,:,:,:].min()\n","        maps_max = feature_map[0,:,:,:].max()\n","        for i in range(n_features):\n","            y = feature_map[0, :, :, i]\n","            y -= y.mean()\n","            if n_features > 2:\n","                y /= y.std()\n","                y *= 64\n","                y += 128\n","            else:\n","                y = (y - maps_min) / (maps_max - maps_min) * 255\n","            y = np.clip(y, 0, 255)\n","            y[(y > 118) & (y < 138)] = np.nan\n","            display_grid[:, i * size : (i + 1) * size] = y\n","\n","        if n_features > 2:\n","            scale = 20. / n_features\n","        else:\n","            scale = 4.\n","        plt.figure(figsize=(scale * n_features, scale))\n","        plt.title(layer_name)\n","        plt.grid(False)\n","        plt.imshow(np.tile(np.array(img_in.resize((size,size))), (1, n_features, 1)), aspect='auto', cmap='gray')\n","        plt.gca().imshow(display_grid, aspect='auto', alpha=0.5, cmap='viridis') #cmap='jet')\n","\n","pred = model.predict(x)\n","cid_pred = np.argmax(pred[0])\n","pred_class_name = cid_to_class_name[cid_pred]\n","print(\"Ground truth: \" + gt_class_name + \" \" + str(pred[0]) + \"  Predicted label: \" + pred_class_name)\n","plt.figure()\n","plt.imshow(img_in, cmap='gray', vmin=-1, vmax=1)\n","plt.axis('off')\n","plt.title(pred_class_name + '\\n[%.2f, %.2f]' % (pred[0][0], pred[0][1]), \n","          color='blue' if pred_class_name == gt_class_name else 'red')\n","plt.tight_layout()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yxdeR8sQMXoo","colab_type":"text"},"source":["##Save and download your best model\n","### You need the h5 file to get the private score."]},{"cell_type":"code","metadata":{"id":"9foYESD7MTeg","colab_type":"code","colab":{}},"source":["# Retry if fails.\n","import time\n","modelname = \"ChestXray_myCNN_\" + time.strftime(\"%Y%m%d-%H%M%S\") + \".h5\"\n","model.save(modelname)\n","\n","from google.colab import files\n","files.download(modelname)"],"execution_count":0,"outputs":[]}]}