{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_GaussianNaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UTNIg2oEn2n8"
      },
      "cell_type": "markdown",
      "source": [
        "# ガウス単純ベイズ識別（Gaussian naive Bayes classification）\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "基本課題（必須）\n",
        "\n",
        "    1. 「★scikit-learn を用いたガウス単純ベイズ識別」まで実行すると，何を表す数値と図が出力されますか．\n",
        "       また，表示される数値と図から何が言えますか．特に，Example 2について記述してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. 「★事前確率の計算」と「★標本平均と標本分散の計算」を完成させてください．\n",
        "       また，その実行結果が，「★scikit-learn を用いたガウス単純ベイズ識別」で表示される \n",
        "       \"Prior probs\"，\"Mean\"，\"Variance\" と一致することを確認してください．\n",
        "\n",
        "（回答は「★事前確率の計算」と「★標本平均と標本分散の計算」に書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 「★scikit-learn を用いたガウス単純ベイズ識別」または「★確率密度の比較」で表示される決定境界は，\n",
        "       どのような曲線があり得るでしょうか．色々な設定でExampleを観察して確認してください．\n",
        "\n",
        "（ここに回答を書いてください）  \n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことを書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title グラフを描くクラス `plot2cls` を定義します（理解不要）．\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import TwoSlopeNorm as tsn\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")#, category=np.VisibleDeprecationWarning)\n",
        "\n",
        "class plot2cls:\n",
        "    def __init__(self, X_train, y_train, decision_function=None, X_val=None, y_val=None, dx=0.02, cmap=plt.cm.bwr, xlim=None, ylim=None, margin=0.5, levels={0.0:'-'}, colors='k', bins=None):\n",
        "        self.data = {'train': {'X': X_train, 'y': y_train}, 'val': {'X':X_val, 'y': y_val}}\n",
        "        self.clf = decision_function\n",
        "        if X_val is not None:\n",
        "            xlim = [X_val[:, 0].min(), X_val[:, 0].max()]\n",
        "            ylim = [X_val[:, 1].min(), X_val[:, 1].max()]\n",
        "        else:\n",
        "            xlim = [float('inf'), - float('inf')]\n",
        "            ylim = [float('inf'), - float('inf')]\n",
        "        xlim[0] = min(xlim[0], X_train[:, 0].min()) - margin\n",
        "        xlim[1] = max(xlim[1], X_train[:, 0].max()) + margin\n",
        "        ylim[0] = min(ylim[0], X_train[:, 1].min()) - margin\n",
        "        ylim[1] = max(ylim[1], X_train[:, 1].max()) + margin\n",
        "        if bins is None:\n",
        "            bins = len(y_train) // 4\n",
        "        self.layout = {'dx': dx, 'cmap': cmap, 'xlim': xlim, 'ylim': ylim, 'levels': levels, 'colors': colors, 'bins': bins}\n",
        "\n",
        "\n",
        "    def _data_layout(self, ax, bbox_to_anchor, loc):\n",
        "        ax.set_xlim(self.layout['xlim'][0], self.layout['xlim'][1])\n",
        "        ax.set_ylim(self.layout['ylim'][0], self.layout['ylim'][1])\n",
        "        #plt.axis('tight')\n",
        "        ax.set_xlabel('x1', fontsize=16)\n",
        "        ax.set_ylabel('x2', fontsize=16)\n",
        "        ax.tick_params(axis='x', labelsize=16)\n",
        "        ax.tick_params(axis='y', labelsize=16)\n",
        "        ax.set_aspect('equal')\n",
        "        #ax.legend(bbox_to_anchor=(1.5,1.0), loc=\"upper right\", fontsize=16, frameon=True)\n",
        "        ax.legend(bbox_to_anchor=bbox_to_anchor, loc=loc, fontsize=16, frameon=True)\n",
        "        if self.data['val']['X'] is not None and self.data['val']['y'] is not None:\n",
        "            ax.legend(bbox_to_anchor=bbox_to_anchor, loc=loc, fontsize=16, frameon=True, ncol=2)\n",
        "            ax.get_legend().legendHandles[2].set_color('k')\n",
        "            ax.get_legend().legendHandles[3].set_color('k')\n",
        "        plt.tight_layout()\n",
        "\n",
        "\n",
        "    def _scatter(self, ax, X, y, c=['r', 'b'], marker=['s', 'o'], label=None, alpha=1):\n",
        "        ax.scatter(X[y>0, 0], X[y>0, 1], c=c[0],  marker=marker[0], cmap=self.layout['cmap'], edgecolors='k', label=label+'(+)', alpha=alpha)\n",
        "        ax.scatter(X[y<=0, 0], X[y<=0, 1], c=c[1], marker=marker[1], cmap=self.layout['cmap'], edgecolors='k', label=label+'(-)', alpha=alpha)\n",
        "\n",
        "\n",
        "    def _put_data(self, ax, alpha):\n",
        "        if self.clf is not None and self.layout['levels'] is not None:\n",
        "            xx, yy = np.meshgrid(np.arange(self.layout['xlim'][0], self.layout['xlim'][1], self.layout['dx']), np.arange(self.layout['ylim'][0], self.layout['ylim'][1], self.layout['dx']))\n",
        "\n",
        "            # Show prediction by color by assigning a color to each point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "            Z = self.clf(np.c_[xx.ravel(), yy.ravel()])\n",
        "            # Put the result into a color plot\n",
        "            Z = Z.reshape(xx.shape)\n",
        "            norm = tsn(vmin=np.minimum(Z[:].min(),-1e-6), vcenter=0, vmax=np.maximum(Z[:].max(),1e-6))\n",
        "            if self.layout['cmap'] is not None:\n",
        "                ax.pcolor(xx, yy, Z, cmap=self.layout['cmap'], alpha=0.1, edgecolors=None, norm=norm)\n",
        "            lvls = list(self.layout['levels'].keys())\n",
        "            linestyles = list(self.layout['levels'].values())\n",
        "            ax.contour(xx, yy, Z, levels=lvls, colors=self.layout['colors'], linestyles=linestyles, alpha=0.5)\n",
        "\n",
        "        self._scatter(ax, self.data['train']['X'], self.data['train']['y'], label='train', alpha=alpha)\n",
        "        if self.data['val']['X'] is not None and self.data['val']['y'] is not None:\n",
        "            self._scatter(ax, self.data['val']['X'], self.data['val']['y'], c=['k', 'k'], label='val', alpha=alpha*0.2)\n",
        "\n",
        "\n",
        "    def plot_data(self, bbox_to_anchor=(1,0), loc=\"lower left\"):\n",
        "        ax = plt.figure(figsize=(8,8))\n",
        "        ax = plt.axes()\n",
        "        self._put_data(ax, alpha=1)\n",
        "        self._data_layout(ax, bbox_to_anchor=bbox_to_anchor, loc=loc)\n",
        "\n",
        "\n",
        "    def _hist_layout(self, ax, bbox_to_anchor, loc, xlabel):\n",
        "        ax.set_xlabel(xlabel, fontsize=16)\n",
        "        ax.set_ylabel(\"Frequency\", fontsize=16)\n",
        "        #ax.axis('tight')\n",
        "        ax.tick_params(axis='x', labelsize=16)\n",
        "        ax.tick_params(axis='y', labelsize=16)\n",
        "        #plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%1.0f'))\n",
        "        from matplotlib.ticker import FormatStrFormatter\n",
        "        ax.yaxis.set_major_formatter(FormatStrFormatter('%1.0f'))\n",
        "        #ax.set_aspect(1)\n",
        "        ax.legend(bbox_to_anchor=bbox_to_anchor, loc=loc, fontsize=16, frameon=True)\n",
        "        if self.data['val']['X'] is not None and self.data['val']['y'] is not None:\n",
        "            ax.legend(bbox_to_anchor=bbox_to_anchor, loc=loc, fontsize=16, frameon=True, ncol=2)\n",
        "            #ax.legend(ncol=2)\n",
        "        plt.tight_layout()\n",
        "\n",
        "\n",
        "    def _make_hist(self, ax):\n",
        "        if self.clf is None:\n",
        "            return\n",
        "        pred = self.clf(self.data['train']['X'])\n",
        "        gt = self.data['train']['y']\n",
        "        ax.hist( [ pred[gt>0], pred[gt<=0] ], bins=self.layout['bins'], histtype='stepfilled', density=False, alpha=0.5, color=['r', 'b'], label=['train(+)', 'train(-)'])\n",
        "        if self.data['val']['X'] is not None and self.data['val']['y'] is not None:\n",
        "            pred = self.clf(self.data['val']['X'])\n",
        "            gt = self.data['val']['y']\n",
        "            ax.hist( [ pred[gt>0], pred[gt<=0] ], bins=self.layout['bins'], histtype='stepfilled', density=False, alpha=0.3, color=['r', 'b'], label=['val(+)', 'val(-)'])\n",
        "\n",
        "\n",
        "    def plot_hist(self, loc=\"lower left\", bbox_to_anchor=(0,1), xlabel=\"$g(x)$\"):\n",
        "        ax = plt.figure(figsize=(6,6))\n",
        "        ax = plt.axes()\n",
        "        self._make_hist(ax)\n",
        "        self._hist_layout(ax,bbox_to_anchor, loc, xlabel)\n",
        "\n",
        "\n",
        "    def plot_clf(self, loc=\"lower left\", bbox_to_anchor=(0,1), xlabel=\"$g(x)$\"):\n",
        "        if self.clf is None:\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=(12,6), nrows=1, ncols=2)\n",
        "        #fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "        ax = axes[0]\n",
        "        self._put_data(ax, alpha=1)\n",
        "        self._data_layout(ax, bbox_to_anchor, loc)\n",
        "\n",
        "        #fig.set_figwidth(12)\n",
        "        #fig.set_figheight(8)\n",
        "        ax = axes[1]\n",
        "        self._make_hist(ax)\n",
        "        self._hist_layout(ax, bbox_to_anchor, loc, xlabel)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kkKF2Idqdx_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実験用のデータ（2次元，2クラス）を生成します．\n",
        "- Example 2～5 からひとつ選んで実行してください．"
      ],
      "metadata": {
        "id": "4byvUzevPKta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: draw npos and nneg points from the Gaussian distribution for each class\n",
        "npos = 100\n",
        "nneg = 500\n",
        "np.random.seed(321)\n",
        "X_all = np.r_[np.random.randn(npos, 2) + [3, 3], np.random.randn(nneg, 2)]\n",
        "# [1,1,...,1,-1,-1,...,-1]\n",
        "y_all = np.array([1] * npos + [-1] * nneg)"
      ],
      "metadata": {
        "id": "6Q4806RKCU7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: create moons using sklearn\n",
        "from sklearn.datasets import make_moons\n",
        "X_all, y_all = make_moons(n_samples=300, noise=0.3, random_state=0)\n",
        "y_all[y_all==0] = -1"
      ],
      "metadata": {
        "id": "El3O6QFrSvrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4: create circles using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "X_all, y_all = make_circles(n_samples=300, noise=0.2, random_state=0, factor=0.3)\n",
        "y_all[y_all==0] = -1"
      ],
      "metadata": {
        "id": "UtEIqFfpSv2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5: combined dataset\n",
        "from sklearn.datasets import make_moons\n",
        "X_all, y_all = make_moons(n_samples=100, noise=0.2, random_state=0)\n",
        "y_all[y_all==0] = -1\n",
        "npos, nneg = 30, 300\n",
        "np.random.seed(321)\n",
        "X_all = np.vstack((2*X_all+np.array([4,-2]), np.r_[np.random.randn(npos, 2) + [3, 3], np.random.randn(nneg, 2)]))\n",
        "# [1,1,...,1,-1,-1,...,-1]\n",
        "y_all = np.hstack((y_all, np.array([1] * npos + [-1] * nneg)))"
      ],
      "metadata": {
        "id": "XnO36S5TTHaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練データ集合 `(X,y)` と検証データ集合 `(X_val,y_val)` に分けます．"
      ],
      "metadata": {
        "id": "5Wy99TN4U4nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, X_val, y, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=0)\n",
        "print(\"#train&val, #test =\", X.shape[0], \",\", X_val.shape[0])"
      ],
      "metadata": {
        "id": "01dspwoN6QI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データを表示します．\n",
        "print(\"#X_all =\", X_all.shape[0])\n",
        "plot2cls(X, y, X_val=X_val, y_val=y_val).plot_data()"
      ],
      "metadata": {
        "id": "dCj3rKLVdyQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★scikit-learn を用いたガウス単純ベイズ識別\n",
        "\n",
        "[sklearn.naive_bayes.GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)を使用した結果を出力します．"
      ],
      "metadata": {
        "id": "ssqJLogmRkli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X,y)\n",
        "\n",
        "# クラス数（number of classes）\n",
        "print(\"# of classes: \", len(model.class_count_))\n",
        "\n",
        "# 各クラスの事前確率（prior probability of each class）\n",
        "print(\"Prior probs: \", model.class_prior_)\n",
        "\n",
        "# 各クラスの各特徴の標本平均と標本分散（mean and variance of each feature per class）\n",
        "print(\"Mean: \", model.theta_.tolist())\n",
        "print(\"Variance: \", model.var_.tolist())\n",
        "\n",
        "print(\"Accuracy on training data: \", model.score(X, y))\n",
        "print(\"Accuracy on validation data: \", model.score(X_val, y_val))\n",
        "\n",
        "dec = lambda X: np.diff(model.predict_proba(X))\n",
        "plot2cls(X, y, dec, X_val, y_val).plot_clf()"
      ],
      "metadata": {
        "id": "3v25MiAACVAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 混同行列（行：正解，列：予測）\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(y_val, model.predict(X_val))\n",
        "print(cm)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val, model.predict(X_val)))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OEW60TwfE4Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ガウス単純ベイズ識別の計算を確認しましょう．\n",
        "\n",
        "生成確率密度 $P(x|Y)=P(x_1|Y)P(x_2|Y)$, \n",
        "\n",
        "各クラスの各特徴の生成確率密度 $P(x_i|Y) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{i|Y}}\\exp\\left\\{-\\frac{(x_i-\\mu_{i|Y})^2}{2\\sigma_{i|Y}^2}\\right\\}$ （ただし，$Y\\in\\{+,-\\}$, $i\\in\\{1,2\\}$）\n",
        "\n",
        "- **★事前確率の計算**：各クラスのデータ数の割合P(Y)を求めます．\n",
        "- **★標本平均と標本分散の計算**：特徴が独立に正規分布することを仮定して，各クラスの訓練データから各特徴の標本平均（sample mean）$\\mu_{1|+}$, $\\mu_{2|+}$, $\\mu_{1|-}$, $\\mu_{2|-}$と，標本分散（sample variance）$\\sigma_{1|+}$, $\\sigma_{2|+}$, $\\sigma_{1|-}$, $\\sigma_{2|-}$を求めます（統計的学習）．\n",
        "- **★確率密度の比較**：各クラスの事後確率密度を比較します（統計的推論）．事後確率密度の代わりに同時確率密度 $P(x,Y) = P(x|Y)P(Y)$ を計算します．"
      ],
      "metadata": {
        "id": "vNfWsVFhCENI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★事前確率の計算\n",
        "\n",
        "- 2クラスのデータは `X_p = X[y>0]` と `X_n = X[y<=0]` です．その各行は2次元の特徴ベクトル x です．\n",
        "- クラス$+$ (`y>0`) と$-$ (`y<=0`) のデータ数の割合を `Prior[0]` と`Prior[1]` とします．"
      ],
      "metadata": {
        "id": "leDx42I4-YHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_p = X[y>0]\n",
        "X_n = X[y<=0]\n",
        "print(X_p.shape, X_n.shape)\n",
        "\n",
        "Prior = np.zeros(2)\n",
        "Prior[0], Prior[1] = ''' 事前確率を計算してください '''\n",
        "\n",
        "print(\"Prior =\", Prior)"
      ],
      "metadata": {
        "id": "IKL9mMXD_61d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★標本平均と標本分散の計算\n",
        "\n",
        "- 2クラスのデータは `X_p = X[y>0]` と `X_n = X[y<=0]` です．その各行は2次元の特徴ベクトルです．\n",
        "- 標本平均ベクトルをそれぞれ `mu_p`，`mu_n` とします（`mu_p.shape` と `mu_n.shape` は `(2,)` です）．それぞれ，標本平均ベクトル$[\\mu_{1|+},\\mu_{2|+}]^\\top$と$[\\mu_{1|-},\\mu_{2|-}]^\\top$を表します．\n",
        "- `X_p` と `X_n` の各特徴の標本分散をそれぞれ `s_p`，`s_n` とします．`s_p.shape` と `s_n.shape` は `(2,)` です．"
      ],
      "metadata": {
        "id": "7f-02r4o1llQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu_p = ''' X_p から標本平均を計算してください ''' \n",
        "print(\"[mu1_p, mu2_p] = \", mu_p)\n",
        "\n",
        "s_p = ''' X_p から標本分散を計算してください '''\n",
        "print(\"[s11_p, s22_p] = \", s_p)\n",
        "\n",
        "mu_n = ''' X_p から標本平均を計算してください '''\n",
        "print(\"[mu1_n, mu2_n] = \", mu_n)\n",
        "\n",
        "s_n = ''' X_n から標本分散を計算してください '''\n",
        "print(\"[s11_n, s22_n] = \", s_n)\n"
      ],
      "metadata": {
        "id": "SaqVSGrICQ5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★確率密度の比較\n",
        "\n",
        "- 計算した事前確率，標本平均，標本分散を用いて，データと共に正規分布と境界を図示します．\n",
        "- 表示した領域内の多数の点で，各クラスの生成分布の確率密度を計算し（統計的推論），確率密度を色の濃さと等高線で表します．"
      ],
      "metadata": {
        "id": "x8VYPj0pA9O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 各クラスの2次元ガウス分布を図示する関数 `plot2d_GaussianNB` を定義します（理解不要）．\n",
        "import numpy as np\n",
        "# Independent bivariate normal joint density\n",
        "def N2d(x, mu, variance):\n",
        "    return np.exp(-0.5 * (x[:,0] - mu[0])**2 / variance[0])  *  np.exp(-0.5 * (x[:,1] - mu[1])**2 / variance[1])  /  (2. * np.pi * np.sqrt(variance[0]*variance[1]))\n",
        "    #return np.exp(-0.5 * (x[:,0] - mu[0])**2 / variance[0])  *  np.exp(-0.5 * (x[:,1] - mu[1])**2 / variance[1])\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "# Visualization of the estimated distributions\n",
        "def plot2d_GaussianNB(X_train, y_train, pri, mus, vars, X_val=None, y_val=None, cmap=None, xlim=None, ylim=None, levels=None, linestyles=None, markers=None, colors=None):\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    ax = plt.axes()\n",
        "\n",
        "    dlim = np.sqrt(vars).sum(axis=0)/2\n",
        "    dxlim, dylim = dlim[0], dlim[1]\n",
        "\n",
        "    if xlim is None:\n",
        "        xlim = [X_train[:, 0].min() - dxlim, X_train[:, 0].max() + dxlim]\n",
        "    if ylim is None:\n",
        "        ylim = [X_train[:, 1].min() - dylim, X_train[:, 1].max() + dylim]\n",
        "\n",
        "    xg, yg = np.arange(xlim[0], xlim[1], (xlim[1]-xlim[0])/300.), np.arange(ylim[0], ylim[1], (ylim[1]-ylim[0])/300.)\n",
        "    xx, yy = np.meshgrid(xg, yg)\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = ['Reds', 'Blues', 'Greens', 'BuPu', 'RdPu', 'YlGn']\n",
        "    if markers is None:\n",
        "        markers = ['o', 's', '^', '*', '+', 'x']\n",
        "    if colors is None:\n",
        "        colors = ['b', 'r', 'g', 'c', 'm', 'y']\n",
        "    ncmap, nm, nc = len(cmap), len(markers), len(colors)\n",
        "\n",
        "    ncls = len(pri)\n",
        "    vmax = 1.  / (2. * np.pi * np.sqrt(vars[:,0] * vars[:,1]))\n",
        "    for k in range(ncls):\n",
        "        #mean and variance of each feature per class\n",
        "        mu = mus[k,:]\n",
        "        variance = vars[k,:]\n",
        "        Z = N2d(np.c_[xx.ravel(),yy.ravel()], mu, variance)\n",
        "\n",
        "        # Put the result into a color plot\n",
        "        #ax.pcolor(xx, yy, Z, cmap=cmap[k], alpha=0.5, edgecolors=None)\n",
        "        Zm = np.ma.masked_array(Z, Z < 0.03*vmax[k])\n",
        "        ax.pcolorfast(xg, yg, Zm.reshape(xx.shape), cmap=cmap[k%ncmap], alpha=0.5)\n",
        "        if levels is not None:\n",
        "            ax.contour(xx, yy, Z.reshape(xx.shape), levels=levels, colors='k', linestyles=linestyles, alpha=0.2)\n",
        "        else:\n",
        "            levels = np.arange(0, vmax[k], vmax[k]/8.)\n",
        "            ax.contour(xx, yy, Z.reshape(xx.shape), levels=levels, colors='k', linestyles=linestyles, alpha=0.2)\n",
        "\n",
        "    if ncls == 2:\n",
        "        decision_function = lambda x: N2d(x, mus[1], vars[1])*pri[1] - N2d(x, mus[0], vars[0])*pri[0]\n",
        "        Z = decision_function(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "        ax.contour(xx, yy, Z.reshape(xx.shape), levels=[0.], colors='k', linestyles=['--'], alpha=1)\n",
        "\n",
        "    # Plot also the training points\n",
        "    y = np.unique(y_train)\n",
        "    for k in range(ncls):\n",
        "        ax.scatter(X_train[y_train==y[k], 0], X_train[y_train==y[k], 1], c=colors[k%nc],  marker=markers[k%nm], cmap=cmap[k%ncmap], edgecolors='k', label='Training data', alpha=1)\n",
        "    # and val points if given\n",
        "    if X_val is not None and y_val is not None:\n",
        "        y = np.unique(y_train)\n",
        "        for k in range(ncls):\n",
        "            ax.scatter(X_val[y_val==y[k], 0], X_val[y_val==y[k], 1], c='k', marker=markers[k%nm], cmap=cmap[k], edgecolors='k', label='Val data', alpha=0.2)\n",
        "        plt.legend(loc=\"upper right\", fontsize=16, frameon=True, bbox_to_anchor=(0,1))\n",
        "\n",
        "    ax.set_xlim(xx.min(), xx.max())\n",
        "    ax.set_ylim(yy.min(), yy.max())\n",
        "    plt.axis('tight')\n",
        "    plt.xlabel('x1', fontsize=16)\n",
        "    plt.ylabel('x2', fontsize=16)\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.gca().set_aspect('equal')\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig('rnd2d_ex1_GNB.png', transparent=True,dpi=300)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J2Ijo29BCVH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot2d_GaussianNB(X, y, Prior, np.c_[mu_p, mu_n].T, np.c_[s_p, s_n].T, X_val, y_val)"
      ],
      "metadata": {
        "id": "DRyJc-kwIJ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMF7nLseKDaV"
      },
      "source": [
        "----\n",
        "## 付録：2変量正規分布（Bivariate normal distribution）\n",
        "\n",
        "${\\rm N}(\\mathbf{x};\\mathbf{\\mu},\\mathbf{\\Sigma})=\\dfrac{1}{\\sqrt{(2\\pi)^m|\\mathbf{\\Sigma}|}}\\,e^{-\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu})^\\top\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu})}$\n",
        "\n",
        "$\\mathbf{x}=\\left[\\matrix{x_1\\\\x_2}\\right]$, $\\mathbf{\\mu}=\\left[\\matrix{\\mu_1\\\\\\mu_2}\\right]$, $\\mathbf{\\Sigma}=\\left[\\matrix{s_{11}&s_{12}\\\\s_{21}&s_{22}}\\right]$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trFp-YcRKVgP",
        "cellView": "form"
      },
      "source": [
        "#@title  { run: \"auto\" }\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "mu1 = 0 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "mu2 = 0 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "s11 = 1 #@param {type:\"slider\", min:0.00, max:4, step:0.1}\n",
        "s12 = 0 #@param {type:\"slider\", min:-4, max:4, step:0.1}\n",
        "s22 = 1 #@param {type:\"slider\", min:0.00, max:4, step:0.1}\n",
        "\n",
        "if s12*s12 >= s11*s22:\n",
        "    print(\"s12*s12 must be smaller than s11*s22\")\n",
        "    s12 = np.sign(s12)*(s11*s22-1e-8)\n",
        "\n",
        "xmin, xmax = -5,5\n",
        "x1, x2 = np.mgrid[xmin:xmax:.01, xmin:xmax:.01]\n",
        "x = np.dstack((x1, x2))\n",
        "\n",
        "prob = stats.multivariate_normal([mu1, mu2], [[s11, s12], [s12, s22]])\n",
        "\n",
        "plt.figure()\n",
        "ax = plt.axes()\n",
        "\n",
        "ax.contourf(x1, x2, prob.pdf(x), alpha=0.9, cmap=plt.cm.Greens)\n",
        "label = '$\\\\mu=$['+\"{:.2f}\".format(mu1)+', '+\"{:.2f}\".format(mu2)+']\\n$\\\\Sigma=$[['+\"{:.2f}\".format(s11)+', '+\"{:.2f}\".format(s12)+']\\n        ['+\"{:.2f}\".format(s12)+', '+\"{:.2f}\".format(s22)+']]'\n",
        "plt.text(1, 3, label, fontsize=16)\n",
        "plt.xlim(xmin, xmax)\n",
        "plt.ylim(xmin, xmax)\n",
        "plt.grid(True, ls='--', lw=0.5, color='k')\n",
        "plt.xlabel(\"$x_1$\", fontsize=20)\n",
        "plt.ylabel(\"$x_2$\", fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "ax.set_aspect('equal')\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "SiU6AigwuemU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "h4Xq7nKCMeqN"
      }
    }
  ]
}