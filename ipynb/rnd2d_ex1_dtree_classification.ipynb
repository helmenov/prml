{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnd2d_ex1_dtree_classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/rnd2d_ex1_dtree_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Xf5xoadG9Z0",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UW1hl94VG9Z8"
      },
      "source": [
        "Classification by decision tree\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PCg8jJ2AG9aH"
      },
      "source": [
        "Define functions\n",
        "----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-PbAn1DPG9aX",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Define functions to visualize classification results\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "# Visualization of the decision boundary and regions\n",
        "def plot2d_classification(decision_function, X_train, y_train, X_test=None, y_test=None, w=None, cmap=plt.cm.bwr, xlim=None, ylim=None, levels=None, colors='k', linestyles=None):\n",
        "\n",
        "    plt.figure()\n",
        "    ax = plt.axes()\n",
        "\n",
        "    if xlim is None:\n",
        "        xlim = [X_train[:, 0].min() - .5, X_train[:, 0].max() + .5]\n",
        "    if ylim is None:\n",
        "        ylim = [X_train[:, 1].min() - .5, X_train[:, 1].max() + .5]\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(xlim[0], xlim[1], 0.02), np.arange(ylim[0], ylim[1], 0.02))    \n",
        "\n",
        "    # Show prediction (P(y=+1 | X) by color by assigning a color to each point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    Z = decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    if levels is not None:\n",
        "        ax.contour(xx, yy, Z, levels=levels, colors=colors, linestyles=linestyles, alpha=1)\n",
        "    else:\n",
        "        ax.pcolor(xx, yy, Z, cmap=cmap, alpha=0.1, edgecolors=None)\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    if w is not None:\n",
        "        x1 = np.linspace(xx.min(), xx.max(), 1000)\n",
        "        x2 = -(w[0] + w[1] * x1) / w[2]\n",
        "        cnd = np.logical_and(x2<yy.max(), x2>yy.min())\n",
        "        plt.plot(x1[cnd], x2[cnd], 'k-')\n",
        "        plt.axvline(x=1.22, color='k')\n",
        "\n",
        "    # Plot also the training points\n",
        "    ax.scatter(X_train[y_train>0, 0], X_train[y_train>0, 1], c='r',  marker='s', cmap=cmap, edgecolors='k', label='Training data', alpha=1)\n",
        "    ax.scatter(X_train[y_train<=0, 0], X_train[y_train<=0, 1], c='b', marker='o', cmap=cmap, edgecolors='k', label='Training data', alpha=1)\n",
        "    # and testing points if given\n",
        "    if X_test is not None and y_test is not None:\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap, edgecolors='k',label='Test data', marker='x', alpha=0.3)\n",
        "        plt.legend(loc=\"upper right\", fontsize=16, frameon=True)\n",
        "        ax.get_legend().legendHandles[0].set_color('k')\n",
        "        ax.get_legend().legendHandles[1].set_color('k')\n",
        "\n",
        "    ax.set_xlim(xx.min(), xx.max())\n",
        "    ax.set_ylim(yy.min(), yy.max())\n",
        "    plt.axis('tight')\n",
        "    plt.xlabel('x1', fontsize=16)\n",
        "    plt.ylabel('x2', fontsize=16)\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.gca().set_aspect('equal')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def  histogram_predict(decision_function, X_train, y_train, X_test=None, y_test=None, bins=None, normed=False):\n",
        "    if bins is None:\n",
        "        bins = len(y_train) // 4\n",
        "    plt.figure()\n",
        "    ax = plt.axes()\n",
        "    pred = decision_function(X_train)\n",
        "    plt.hist( [ pred[y_train>0], pred[y_train<=0] ], bins=bins, histtype='stepfilled', density=False, alpha=0.5, color=['r', 'b'], label=['$y=+1$', '$y=-1$'])\n",
        "    if X_test is not None and y_test is not None:\n",
        "        pred = decision_function(X_test)\n",
        "        plt.hist( [ pred[y_test>0], pred[y_test<=0] ], bins=bins, histtype='stepfilled', density=False, alpha=0.3, color=['r', 'b'], label=['$y_{test}=+1$', '$y_{test}=-1$'])\n",
        "    plt.xlabel(\"$g(x)$\", fontsize=16)\n",
        "    plt.ylabel(\"Frequency\", fontsize=16)\n",
        "    plt.legend(loc=\"upper right\", fontsize=16, frameon=True)\n",
        "    plt.axis('tight')\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    from matplotlib.ticker import FormatStrFormatter\n",
        "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%1.0f'))\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def show_dtree_structure(model):\n",
        "    n_nodes = model.tree_.node_count\n",
        "    children_left = model.tree_.children_left\n",
        "    children_right = model.tree_.children_right\n",
        "    feature = model.tree_.feature\n",
        "    threshold = model.tree_.threshold\n",
        "\n",
        "    node_depth = np.zeros(shape=n_nodes,dtype=np.int64)\n",
        "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
        "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
        "    while len(stack) > 0:\n",
        "        node_id, parent_depth = stack.pop()\n",
        "        node_depth[node_id] = parent_depth + 1\n",
        "\n",
        "        # If we have a test node\n",
        "        if (children_left[node_id] != children_right[node_id]):\n",
        "            stack.append((children_left[node_id], parent_depth + 1))\n",
        "            stack.append((children_right[node_id], parent_depth + 1))\n",
        "        else:\n",
        "            is_leaves[node_id] = True\n",
        "\n",
        "    print(\"The binary tree structure has %s nodes and has the following tree structure:\" % n_nodes)\n",
        "    for i in range(n_nodes):\n",
        "        if is_leaves[i]:\n",
        "            print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
        "        else:\n",
        "            if feature[i] == 0:\n",
        "                print(\"%snode=%s test node: go to node %s if x1 <= %.2f else to node %s.\" % (node_depth[i] * \"\\t\", i, children_left[i], threshold[i], children_right[i] ))\n",
        "            elif feature[i] == 1:\n",
        "                print(\"%snode=%s test node: go to node %s if x2 <= %.2f else to node %s.\" % (node_depth[i] * \"\\t\", i, children_left[i], threshold[i], children_right[i] ))\n",
        "            else:\n",
        "                print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to node %s.\" % (node_depth[i] * \"\\t\", i, children_left[i], feature[i], threshold[i], children_right[i] ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "obFLzXN6G9Z_"
      },
      "source": [
        "Make training data\n",
        "------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aQWiGCU0G9aA",
        "colab": {}
      },
      "source": [
        "# Example 1: define manually\n",
        "X = np.array([[0, 0], [1,0], [0,1], [1,1]])\n",
        "y = np.array([-1,1,1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qPcFoZwoU2fp",
        "colab": {}
      },
      "source": [
        "# Example 2: draw npos and nneg points from the Gaussian distribution for each class\n",
        "npos = 30\n",
        "nneg = 30\n",
        "np.random.seed(432)\n",
        "X = np.r_[np.random.randn(npos, 2) + [3, 3], np.random.randn(nneg, 2)]\n",
        "# [1,1,...,1,-1,-1,...,-1]\n",
        "y = np.array([1] * npos + [-1] * nneg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IAcLs8fxU3b8",
        "colab": {}
      },
      "source": [
        "# Example 3: create moons using sklearn\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=100, noise=0.3, random_state=0)\n",
        "y[y==0] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3YZ8r-NoiWgB",
        "colab": {}
      },
      "source": [
        "# Example 4: create circles using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(n_samples=150, noise=0.1, random_state=0, factor=0.3)\n",
        "y[y==0] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbqXssHcU5Is"
      },
      "source": [
        "Plot the training points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cl-028CoG9aE",
        "colab": {}
      },
      "source": [
        "# Plot the training points\n",
        "ax = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.scatter(X[y>0, 0], X[y>0, 1], c='r',  marker='s', cmap=plt.cm.bwr, edgecolors='k', label='Training data', alpha=1)\n",
        "ax.scatter(X[y<=0, 0], X[y<=0, 1], c='b', marker='o', cmap=plt.cm.bwr, edgecolors='k', label='Training data', alpha=1)\n",
        "plt.xlabel('x1', fontsize=16)\n",
        "plt.ylabel('x2', fontsize=16)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.gca().set_aspect('equal')\n",
        "ax.set_xlim(X[:,0].min()-0.5, X[:,0].max()+0.5)\n",
        "ax.set_ylim(X[:,1].min()-0.5, X[:,1].max()+0.5)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pT0P8z26G9aT"
      },
      "source": [
        "Run the training\n",
        "----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OA7s-t0MG9ae",
        "colab": {}
      },
      "source": [
        "# Decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "model = DecisionTreeClassifier(max_depth=15, min_samples_leaf=1)\n",
        "model.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eIQAY-CgG9ah",
        "colab": {}
      },
      "source": [
        "# Visualize the decision boundary and margin\n",
        "plot2d_classification(lambda X: model.predict_proba(X)[:,1], X, y)\n",
        "plt.savefig('dtree.png', transparent=True, dpi=300)\n",
        "histogram_predict(lambda X: model.predict_proba(X)[:,1], X, y)\n",
        "plt.savefig('hist_dtree.png', transparent=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sf6zP8EuRrji",
        "colab": {}
      },
      "source": [
        "show_dtree_structure(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}