{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_MNIST_LDAembedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDAによる低次元化（dimensionality reduction by the linear discriminant analysis）\n",
        "\n",
        "MNIST画像集合を線形判別分析（LDA）\n",
        "で識別的な低次元空間に埋め込み，観察します．\n",
        "\n",
        "参考資料：\n",
        "- [Linear discriminant analysis@Wikipedia](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n",
        "- [Linear and Quadratic Discriminant Analysis@scikit-learn](https://scikit-learn.org/stable/modules/lda_qda.html)\n",
        "- [Linear Discriminant Analysis – Bit by Bit](https://sebastianraschka.com/Articles/2014_python_lda.html)\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "## 基本課題（必須）\n",
        "\n",
        "    1. 手書き数字画像MNISTの 1，4，7，9 の4クラスを線形判別分析で低次元化したとき，\n",
        "       第1成分（comp. 1）はこれらのクラスをどのように分類するために役立つ特徴量ですか．\n",
        "       同様に，第2成分（comp. 2）と第3成分（comp. 3）は，それぞれどのクラスについて識別的な特徴量であると言えますか．理由と共に回答してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. Fashion-MNISTについて，線形判別分析でどのクラスが他のクラスと識別し易い・し難いですか．低次元空間における分布と混同行列に基づき調べてください．\n",
        "       また，識別し易い・し難い原因についても考察してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 上記の参考資料等をもとに，線形判別分析による低次元化の原理について調査し，理解できた範囲で解説してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "発展課題（任意）がこのノートブックの後半にあります．"
      ],
      "metadata": {
        "id": "AH8-0BiKPDuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データ集合を取得します．"
      ],
      "metadata": {
        "id": "tC7fn8ijeihu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "# [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
        "tvds = datasets.MNIST('./data', download=True, train=True)\n",
        "\n",
        "# [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
        "#tvds = datasets.FashionMNIST('./data', download=True, train=True)\n",
        "\n",
        "# [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist)\n",
        "#tvds = datasets.KMNIST('./data', download=True, train=True)\n",
        "\n",
        "Ximages_all, y_all = tvds.data.numpy(), tvds.targets.numpy()\n",
        "\n",
        "# [EMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.EMNIST.html)\n",
        "#tvds = datasets.EMNIST('./data', download=True, train=True, split='letters')\n",
        "#Ximages_all, y_all = tvds.data.transpose_(-1,-2).numpy(), tvds.targets.numpy() - 1"
      ],
      "metadata": {
        "id": "pBKK4QZN1eCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ☆画像数とサイズを確認します（画像を加工したい場合はこのセルを編集して利用してください）．\n",
        "\n",
        "# simulate noisy images\n",
        "#Ximages_all = Ximages_all + np.random.rand(*Ximages_all.shape) * 200\n",
        "#Ximages_all[Ximages_all > 255] = 255\n",
        "\n",
        "import numpy as np\n",
        "from skimage.filters import gaussian\n",
        "from skimage.exposure import equalize_hist as eh\n",
        "from skimage.transform import resize\n",
        "\n",
        "'''\n",
        "* blurring (https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian)\n",
        "* histogram equalization (https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html)\n",
        "* resize images (https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html)\n",
        "'''\n",
        "#Ximages_all = gaussian(np.float32(Ximages_all.transpose((1,2,0))), sigma=1.0, multichannel=True).transpose(2,0,1)\n",
        "#Ximages_all = eh(Ximages_all.transpose((1,2,0))).transpose(2,0,1) * 255\n",
        "#height, width = 8, 8; Ximages_all = resize(Ximages_all.transpose((1,2,0)), (height, width)).transpose(2,0,1)\n",
        "\n",
        "Ximages_all = np.uint8(Ximages_all)\n",
        "print(\"(#images, height, width)\", Ximages_all.shape)\n",
        "print(Ximages_all.dtype, \", max. pixel value = \", Ximages_all.max())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9w91jXrgIKuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST class labels\n",
        "\n",
        "| [MNIST](http://yann.lecun.com/exdb/mnist/) | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
        "| - | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) | **T-shirt/top** | Trouser | **Pullover** | Dress | **Coat** | Sandal |  **Shirt** | Sneaker | Bag | Ankle boot |\n",
        "| [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist) | お | き | す | つ | な | は |  ま | や | れ | を |"
      ],
      "metadata": {
        "id": "b85HjGXpQuO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 画像を例示します．\n",
        "#@title Show images of digits\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"%d images in total\" % len(y_all))\n",
        "\n",
        "# show the digits\n",
        "def plotMNIST(imgs, gts, preds=None, num=8, mag=0.6):\n",
        "    classes = np.unique(gts)\n",
        "    nc = len(classes)\n",
        "    idx = np.arange(len(gts))\n",
        "    fig = plt.figure(figsize=(num*mag, nc*mag))  # figure size in inches\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "    for i, c in enumerate(classes):\n",
        "        imgsc = imgs[gts==c]\n",
        "        idc = idx[gts==c]\n",
        "        for j in range(min(num,len(imgsc))):\n",
        "            ax = fig.add_subplot(nc, num, i*num+j+1, xticks=[], yticks=[])\n",
        "            ax.imshow(imgsc[j], cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "            # label the image with the target value\n",
        "            ax.text(0, imgs.shape[1]*0.2, str(c), color='white')\n",
        "            if preds is not None:\n",
        "                if preds[idc[j]] == c:\n",
        "                    ax.text(imgs.shape[2]*0.8, imgs.shape[1]*0.2, str(preds[idc[j]]), color='#a0ffa0')\n",
        "                else:\n",
        "                    ax.text(imgs.shape[2]*0.8, imgs.shape[1]*0.2, str(preds[idc[j]]), color='red')\n",
        "\n",
        "p = np.random.permutation(len(y_all))\n",
        "plotMNIST(Ximages_all[p], y_all[p], num=16)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ivCIQfztnbuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76r4Ic8VAj_g"
      },
      "source": [
        "### 4クラスの識別問題にしたい場合（さもなくば実行しなくてよいです）\n",
        "- このセルの `c0` ～ `c3` でクラスを指定して実行してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVowqB1Z_Pcs"
      },
      "source": [
        "c0 = 1 # choose from 0 to 9\n",
        "c1 = 4 # choose from 0 to 9\n",
        "c2 = 7 # choose from 0 to 9\n",
        "c3 = 9 # choose from 0 to 9\n",
        "\n",
        "Ximages = Ximages_all[np.logical_or.reduce((y_all == c0, y_all == c1, y_all == c2, y_all == c3))]\n",
        "y = y_all[np.logical_or.reduce((y_all == c0, y_all == c1, y_all == c2, y_all == c3))]\n",
        "classes = np.unique(y)\n",
        "\n",
        "p = np.random.permutation(len(y))\n",
        "plotMNIST(Ximages[p], y[p], num=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc7EF1HS_QMb"
      },
      "source": [
        "### すべてのクラスを使いたい場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohWRmfaW_QMc"
      },
      "source": [
        "Ximages = Ximages_all\n",
        "y = y_all\n",
        "classes = np.unique(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ☆訓練データと検証データに分けます．\n",
        "- 画像を `Ximages_train` と `Ximages_val` に分けます．それぞれ `n_train` 枚と `n_val` 枚の画像です．\n",
        "- `Ximages_train` と `Ximages_val` を，それぞれ shape が `(n_train, 画素数)`，`(n_val，画素数)` の NumPy 配列にしたものが `X_train`，`X_val` です．"
      ],
      "metadata": {
        "id": "H9BCD7UEZxet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split the data into training and validation sets\n",
        "Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages, y, train_size=0.8)\n",
        "\n",
        "n_train = len(Ximages_train)\n",
        "n_val = len(Ximages_val)\n",
        "\n",
        "# reshape to 28*28=784-dimensional feature vectors\n",
        "X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1)) / 255   # (n_train, 784)\n",
        "X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1)) / 255         # (n_val, 784)\n",
        "print(\"X_train.shape = \", X_train.shape)\n",
        "print(\"X_val.shape = \", X_val.shape)"
      ],
      "metadata": {
        "id": "Zxtu4nWQZvtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★線形判別分析を実行します（**2次元化の場合**）．\n",
        "- [sklearn.discriminant_analysis.LinearDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)を使用します．引数の仕様とデフォルトの値を確認してください．"
      ],
      "metadata": {
        "id": "3cy3uyS35LYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2次元データ X を y で色分けして正方形内にプロットする関数 plot_embedding2d(X, y) を定義します．\n",
        "# https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#helper-function-to-plot-embedding\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib.colors import TwoSlopeNorm as tsn\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "\n",
        "def plot_embedding2d(X, y, title=\"\", xlabel=\"\", ylabel=\"\", axis=\"on\", xlim=[-3.1, 3.1], ylim=[-3.1, 3.1], Scaler=None):\n",
        "    _, ax = plt.subplots()\n",
        "\n",
        "    if Scaler is None:\n",
        "        Scaler = RobustScaler() # MinMaxScaler(), StandardScaler()\n",
        "        X2d = Scaler.fit_transform(X[:,:2])\n",
        "    else:\n",
        "        X2d = Scaler.transform(X[:,:2])\n",
        "\n",
        "    classes = np.unique(y)\n",
        "    for yi in classes:\n",
        "        ax.scatter(\n",
        "            *X2d[y == yi].T,\n",
        "            marker=f\"${yi}$\",\n",
        "            s=60,\n",
        "            color=plt.cm.tab10(yi), #Paired(yi),\n",
        "            alpha=0.425,\n",
        "            zorder=2,\n",
        "        )\n",
        "\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.axis(axis)\n",
        "    ax.set_aspect(1)\n",
        "\n",
        "    return Scaler\n",
        "\n",
        "#####imshows(model.scalings_[:,:2].T.reshape(-1, Ximages.shape[1], Ximages.shape[2]), robust=True)\n",
        "def imshows(imgs, mag=1.0, cmap=None, robust=True): # imgs (num, height, width)\n",
        "    if cmap is None:\n",
        "        cmap = plt.cm.seismic\n",
        "\n",
        "    if robust:\n",
        "        imgsc = RobustScaler().fit_transform(imgs.reshape(imgs.shape[0],-1)).reshape(-1,imgs.shape[1], imgs.shape[2])\n",
        "    else:\n",
        "        imgsc = imgs\n",
        "\n",
        "    nc = imgsc.shape[0]\n",
        "    fig = plt.figure(figsize=(nc*mag, mag))\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "    vmin, vmax = np.minimum(imgsc.min(),-1e-6), np.maximum(imgsc.max(),1e-6)\n",
        "    print(vmin, vmax)\n",
        "    norm = tsn(vmin=vmin, vcenter=0.5, vmax=vmax)\n",
        "    for i in range(nc):\n",
        "        ax = fig.add_subplot(1, nc, i + 1, xticks=[], yticks=[])\n",
        "        ax.imshow(imgsc[i], cmap=cmap, norm=norm, vmin=vmin,vmax=vmax)\n",
        "        ax.set_title(str(i))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e3OYPRU6qKhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "model = LinearDiscriminantAnalysis(n_components=2)\n",
        "\n",
        "Xe_train = model.fit_transform(X_train, y_train)\n",
        "Xe_val = model.transform(X_val)"
      ],
      "metadata": {
        "id": "A9x3n9YUwW7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 全部表示すると多いので，ランダムに n 個だけ表示する．\n",
        "nt = min(100, n_train)\n",
        "pt = np.random.choice(X_train.shape[0], nt, replace=False)\n",
        "\n",
        "nv = min(100, n_val)\n",
        "pv = np.random.choice(X_val.shape[0], nv, replace=False)\n",
        "\n",
        "sc = plot_embedding2d(Xe_train[pt], y_train[pt], title=\"train\", xlabel=\"comp. 1\", ylabel=\"comp. 2\")\n",
        "plot_embedding2d(Xe_val[pv], y_val[pv], Scaler=sc, title=\"val\", xlabel=\"comp. 1\", ylabel=\"comp. 2\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s620oOhX-4K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★線形判別分析を実行します（**3次元化の場合**）．\n",
        "- [sklearn.discriminant_analysis.LinearDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)を使用します．引数の仕様とデフォルトの値を確認してください．"
      ],
      "metadata": {
        "id": "BmWvxSAyWs4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3次元データ X を y で色分けして立方体内にプロットする関数 plot_embedding3d(X, y) を定義します．\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib import offsetbox\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import plotly.graph_objs  as go\n",
        "import plotly.graph_objs.layout  as gol\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'colab'\n",
        "\n",
        "def plot_embedding3d(X, y, xlim=[-3.1, 3.1], ylim=[-3.1, 3.1], zlim=[-3.1,3.1], Scaler=None):\n",
        "    if Scaler is None:\n",
        "        Scaler = RobustScaler() # MinMaxScaler(), StandardScaler()\n",
        "        X3d = Scaler.fit_transform(X[:,:3])\n",
        "    else:\n",
        "        X3d = Scaler.transform(X[:,:3])\n",
        "\n",
        "    # https://plotly.com/python-api-reference/generated/plotly.graph_objects.Scatter3d.html#plotly.graph_objects.Scatter3d\n",
        "    trace = go.Scatter3d(x=X3d[:,0], y=X3d[:,1], z=X3d[:,2], mode='text',\n",
        "                         text=y, textfont=dict(color=['rgba({},{},{},{})'.format(c[0],c[1],c[2],0.8) for c in plt.cm.tab10(y)]), textposition='top center'\n",
        "    )\n",
        "\n",
        "    layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0), scene=gol.Scene(aspectmode='cube', xaxis=gol.scene.XAxis(title=\"comp. 1\"), yaxis=gol.scene.YAxis(title=\"comp. 2\"), zaxis=gol.scene.ZAxis(title=\"comp. 3\")))\n",
        "    fig = go.Figure(data=[trace], layout=layout)\n",
        "    camera = dict(up=dict(x=0, y=0, z=3), center=dict(x=0, y=0, z=0), eye=dict(x=1.5, y=1.5, z=0.8))\n",
        "    scene = dict(xaxis=dict(range=xlim), yaxis=dict(range=ylim), zaxis=dict(range=zlim))\n",
        "    fig.update_layout(scene_camera=camera, scene=scene)\n",
        "    fig.show()\n",
        "    return Scaler"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VF1Cwp-iWDZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "model = LinearDiscriminantAnalysis(n_components=3)\n",
        "\n",
        "Xe_train = model.fit_transform(X_train, y_train)\n",
        "Xe_val = model.transform(X_val)\n",
        "\n",
        "# 全部表示すると多いので，ランダムに n 個だけ表示する．\n",
        "nt = min(300, n_train)\n",
        "pt = np.random.choice(X_train.shape[0], nt, replace=False)\n",
        "sc = plot_embedding3d(Xe_train[pt], y_train[pt])\n",
        "\n",
        "nv = min(300, n_val)\n",
        "pv = np.random.choice(X_val.shape[0], nv, replace=False)\n",
        "plot_embedding3d(Xe_val[pv], y_val[pv], Scaler=sc)"
      ],
      "metadata": {
        "id": "8R0hwrK2WyYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 識別の結果を例示します（上：訓練データ，下：検証データ）．\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "print(\"Accuracy on training data: \", accuracy_score(y_train, y_pred))\n",
        "p = np.random.permutation(n_train)\n",
        "plotMNIST(Ximages_train[p], y_train[p], y_pred[p], num=16)\n",
        "plt.show()\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "print(\"\\nAccuracy on validation data: \", accuracy_score(y_val, y_pred))\n",
        "p = np.random.permutation(n_val)\n",
        "plotMNIST(Ximages_val[p], y_val[p], y_pred[p], num=16)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Hp6UlrFybtks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST class labels\n",
        "\n",
        "| [MNIST](http://yann.lecun.com/exdb/mnist/) | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
        "| - | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
        "| [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) | T-shirt/top | Trouser | Pullover | Dress | Coat | Sandal |  Shirt | Sneaker | Bag | Ankle boot |\n",
        "| [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist) | お | き | す | つ | な | は |  ま | や | れ | を |"
      ],
      "metadata": {
        "id": "-90fcIXUSjBw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9z76Bdn2oe",
        "cellView": "form"
      },
      "source": [
        "#@title 混同行列（行：正解，列：予測）\n",
        "from sklearn import metrics\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "cm = metrics.confusion_matrix(y_val, y_pred)\n",
        "print(cm)\n",
        "\n",
        "print(cm.sum(axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRUeztQpn2op",
        "cellView": "form"
      },
      "source": [
        "#@title おまけ\n",
        "import seaborn as sns\n",
        "\n",
        "# Make predictions on test data\n",
        "cm = metrics.confusion_matrix(y_val, y_pred)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "## 発展課題（任意）\n",
        "\n",
        "学習済みの畳み込みニューラルネット（DCNN）で画像から抽出した特徴（DCNN特徴）を用いて線形判別分析してみましょう．\n",
        "画素値のまま線形判別分析に用いるよりも，識別し易くなるクラスがあるかもしれません．\n",
        "\n",
        "    1. Fashion-MNISTの 0:T-shirt/top, 2:Pullover, 4:Coat, 6:Shirt の4クラスについて，画素値を用いた場合と，DCNN特徴を用いた場合を比較してください．\n",
        "       識別的な低次元化がし易いのはどちらでしょうか．また，識別の結果はどうですか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. MedMNISTについても，同様に比較・考察しましょう．\n",
        "\n",
        "（ここに回答を書いてください）[参考文献](https://arxiv.org/abs/2110.14795)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2QsruOf_mYxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 学習済みの畳み込みニューラルネットワークで特徴抽出する関数 feature_extractor を定義します．<p><ul><li>「☆訓練データと検証データに分けます．」のセルを実行後に，下のセルで `X_train` と `X_val` を `feature_extractor` で作成してください．</li><li>`X_train` と `X_val` を作成後，「★線形判別分析を実行します」に戻って，線形判別分析による低次元化を実行してください．</li></ul>\n",
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "#model_pretrained = models.alexnet(weights='DEFAULT', progress=False)\n",
        "#model_pretrained = models.vgg16(weights='DEFAULT')\n",
        "#model_pretrained = models.vgg16_bn(weights='DEFAULT')\n",
        "\n",
        "#model_pretrained = models.resnet50(weights='DEFAULT')\n",
        "#model_pretrained = models.googlenet(weights='DEFAULT')\n",
        "#model_pretrained = models.mobilenet_v3_small(weights='DEFAULT')\n",
        "model_pretrained = models.efficientnet_b0(weights='DEFAULT')\n",
        "\n",
        "#feature_extractor = model_pretrained.features\n",
        "\n",
        "class DCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = model_pretrained.features\n",
        "        self.gap = torch.nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.gap(x).squeeze(-1).squeeze(-1) # [B, C, H=1, W=1] -> [B, C]\n",
        "        return x\n",
        "\n",
        "DCNNfeatures = DCNN()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DCNNfeatures.eval().to(device)\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def feature_extractor(Ximages, batch_size=256): # Ximages(n_samples, height, width)\n",
        "    with torch.no_grad():\n",
        "        imgs = torch.tensor(Ximages).to(device)\n",
        "        if Ximages.ndim == 3:\n",
        "            imgs.unsqueeze_(1)\n",
        "            imgs = imgs / 255.0\n",
        "            n, _, h, w = imgs.shape\n",
        "            imgs = imgs.view(n, 1, h, w).expand(-1,3,-1,-1)\n",
        "        else:\n",
        "            imgs = imgs.permute(0,3,1,2)\n",
        "            imgs = transforms.Normalize(mean = [0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(imgs.float())\n",
        "\n",
        "        dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)        \n",
        "        f = []\n",
        "        for bimgs in dataloader:\n",
        "            bimgs = transforms.Resize(112)(bimgs)\n",
        "            x = DCNNfeatures(bimgs.to(device))\n",
        "            f.append(x.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(f)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Cj4gLzRK4suN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴抽出\n",
        "# 注意：数分かかります！ ランタイムのタイプをGPUへ変更することを推奨します．CPUでは，colabのメモリ不足でカーネルがクラッシュすることがあります．\n",
        "X_train = feature_extractor(Ximages_train)\n",
        "X_val = feature_extractor(Ximages_val)"
      ],
      "metadata": {
        "id": "FYQ0KUT-Yz6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [MedMNIST](https://github.com/MedMNIST/MedMNIST)を使う場合<p>以下を実行後，このJupyter Notebook前半の「☆画像数とサイズを確認します（画像を加工したい場合はこのセルを編集して利用してください）．」以降を実行できます．\n",
        "!pip install -q medmnist\n",
        "import medmnist\n",
        "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "19n5ZTkG1eH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'pneumoniamnist', 'chestmnist', 'octmnist', 'breastmnist', 'tissuemnist', 'organamnist', 'organcmnist', 'organsmnist' \n",
        "data_flag = 'retinamnist' # 'octmnist' \n",
        "DataClass = getattr(medmnist, medmnist.INFO[data_flag]['python_class'])\n",
        "\n",
        "tvds = DataClass(split='train', download=True)\n",
        "#tvds = DataClass(split='test', download=True)\n",
        "\n",
        "print(tvds)\n",
        "Ximages_all, y_all = tvds.imgs, tvds.labels.ravel()"
      ],
      "metadata": {
        "id": "2JWf5Htq1eLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "jBz0cgBO0qZM"
      }
    }
  ]
}