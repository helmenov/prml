{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_SRC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# スパース表現に基づく識別（sparse representation-based classification; SRC）\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "- [SRCによる顔認識（スライド）](https://github.com/tsakailab/prml/blob/master/lectures/SRC_tsakai.pdf)\n",
        "- [早わかりスパースモデリング（テキスト）](https://drive.google.com/file/d/0Bx4bEpaTSFcgeU5LNW1rMUZMMDA)\n",
        "- [SRCの原著論文](https://ieeexplore.ieee.org/abstract/document/4483511)の[PDFファイル](http://www.columbia.edu/~jw2966/papers/WYGSM09-PAMI.pdf)\n",
        "\n",
        "\n",
        "目的変数として質問の顔画像が与えられたとき，それを既知の顔画像の簡潔な組合せで説明するスパース回帰分析を考えましょう．質問の顔は，組合せに選ばれた顔と同一人物ではないでしょうか．そんな仕組みの画像認識はSRCと呼ばれています．簡潔な組合せを表す非ゼロの回帰係数（スパース解）が低品質の画像からも求められるので，画質に影響され難い頑健性（robustness）がSRCの特長のひとつです．\n",
        "\n",
        "    1. 「★直交マッチング追跡（orthogonal matching pursuit; OMP）を実装します．」のセルにある関数OMPを完成させてください．\n",
        "\n",
        "（回答は★のセルに書いてください）\n",
        "\n",
        "\n",
        "    2. どのような質問画像に対して，スパース解の非ゼロ成分の数が少ない・多いですか．\n",
        "       また，どのような場合に誤認識しやすいですか．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 欠損率に対してSRCはどの程度頑健ですか．実験的に調べてください．その実験結果は，原著論文の実験評価と同じでしょうか．\n",
        "       異なる場合は，その原因を考察してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことを書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "crTv0jrcIJJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 顔画像データをダウンロードし，訓練画像（説明変数） `X_train` と、質問画像（目的変数） `X_q` に分けます．<p>画像：[cropped Yale face database B](https://paperswithcode.com/dataset/extended-yale-b-1)，32x32画素，2414枚，38人．</p>\n",
        "\n",
        "import requests\n",
        "import io\n",
        "\n",
        "response = requests.get('https://github.com/tsakailab/prml/raw/master/datasets/YaleB_32x32.mat')\n",
        "response.raise_for_status()\n",
        "#data = np.load(io.BytesIO(response.content))\n",
        "from scipy.io import loadmat\n",
        "dataset = loadmat(io.BytesIO(response.content))\n",
        "\n",
        "# split data into those for training (0.5), validation (0.5*0.5) and testing (0.5*0.5)\n",
        "mybirthday = 19731115\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_q, y_train, y_q = train_test_split(dataset['fea'], dataset['gnd'].ravel(), train_size=0.8, random_state=mybirthday)\n",
        "n_train, n_q = X_train.shape[0], X_q.shape[0]\n",
        "n_pixels = X_train.shape[1]\n",
        "print(\"#train =\", n_train, \", #queries =\", n_q)\n",
        "\n",
        "# zero-based indexing, shape (n,)\n",
        "y_train, y_q = y_train-1, y_q-1\n",
        "\n",
        "# scaling to [0,1]\n",
        "X_train, X_q = X_train / 255., X_q / 255."
      ],
      "metadata": {
        "cellView": "form",
        "id": "soiG1ijrWVXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPbdEvDtw_74"
      },
      "source": [
        "### ランダムに画素を欠損させます．\n",
        "- 欠損率 `missing_pixel_rate` を設定してください．\n",
        "- 欠損させた画素は赤で表示されます．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rate of missing pixels\n",
        "missing_pixel_rate = 0.3    #### try 0.1, 0.3, 0.5 ####"
      ],
      "metadata": {
        "id": "jf0ssS3M36G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 訓練画像（training images）と質問画像（query images）を表示します．\n",
        "import numpy as np\n",
        "\n",
        "n_pixels_miss = np.ceil(n_pixels * missing_pixel_rate).astype(int)\n",
        "p_miss = np.random.choice(n_pixels, n_pixels_miss, replace=False)\n",
        "\n",
        "# put np.nan as missing pixels\n",
        "X_in_train = X_train.copy()\n",
        "X_in_train[:,p_miss] = np.nan\n",
        "X_in_q = X_q.copy()\n",
        "X_in_q[:,p_miss] = np.nan\n",
        "p_obs = ~np.isnan(X_in_q[0,:])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.cm.gray.set_bad(color='red')\n",
        "\n",
        "def imshows(X, subplots=(4,6)):\n",
        "    vmin, vmax = 0., 1.\n",
        "    if subplots[0] == 1 and subplots[1] == 1:\n",
        "        plt.matshow(X.reshape(32, 32).T, cmap=plt.cm.gray, vmin=vmin, vmax=vmax)\n",
        "    else:\n",
        "        fig, axes = plt.subplots(subplots[0], subplots[1])\n",
        "        for f, ax in zip(X, axes.ravel()):\n",
        "            ax.matshow(f.reshape(32, 32).T, cmap=plt.cm.gray, vmin=vmin, vmax=vmax)\n",
        "            ax.set_xticks(())\n",
        "            ax.set_yticks(())\n",
        "\n",
        "print(\"Training images,\", p_obs.sum(), \"pixels are available for each\")\n",
        "#print(\"X_in_train.shape =\", X_in_train.shape)\n",
        "imshows(X_in_train)\n",
        "plt.show()\n",
        "\n",
        "print(\"Query images each with\", p_obs.sum(), \"pixels are available for each\")\n",
        "#print(\"X_in_q.shape =\", X_in_q.shape)\n",
        "imshows(X_in_q)"
      ],
      "metadata": {
        "id": "DoDVtOb3Zd_A",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ★直交マッチング追跡（orthogonal matching pursuit; OMP）を実装します．\n",
        "\n",
        "${\\boldsymbol x}^\\star=\\arg\\min_{\\boldsymbol x}\\|\\boldsymbol x\\|_0 \\quad\\mbox{subject to}\\quad \\|{\\boldsymbol b}-{\\boldsymbol{ Ax}}\\|_2\\leq \\delta$\n",
        "\n",
        "を数値計算するスパース解法のひとつです．\n",
        "- [[Pati+93]](https://user.eng.umd.edu/~krishna/images/pati_reza_psk.pdf)\n",
        "- 酒井の解説資料：[スライド](https://github.com/tsakailab/HDsci-SpM/blob/main/seminar/slides/Day03.pdf)，[テキスト](https://github.com/tsakailab/prml/blob/master/lectures/OMP_tsakai.pdf)\n",
        "- 非ゼロ成分の計算は，残差が `delta` 以下または非ゼロが `maxnnz` 個以上になると終了します．"
      ],
      "metadata": {
        "id": "XDerq-ywVjOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import linalg\n",
        "\n",
        "# Orthogonal matching pursuit (OMP)\n",
        "def OMP(A, b, delta=1e-6, maxnnz=None):\n",
        "    d, n = A.shape\n",
        "    if maxnnz is None: maxnnz = d // 2\n",
        "    r = b.copy()\n",
        "    x = np.zeros(n)\n",
        "    supp = []                                   # 台（b の説明に使う A の列の番号のリスト）\n",
        "    while len(supp) < maxnnz and linalg.norm(r) > delta:\n",
        "        t = np.argmax(np.abs( A.T.dot(r) ))     # 残差 r と最も類似する行列 A の列の番号 t\n",
        "        supp.append(t)                          # 台 supp に t を追加する\n",
        "        Asupp = A[:,supp]                       # b の説明に用いる A の列ベクトル  \n",
        "        x[supp] = '''説明変数を Asupp，目的変数を b とする回帰係数の最小二乗解 '''\n",
        "        r = b - Asupp.dot(x[supp])              # 残差の更新\n",
        "    return x"
      ],
      "metadata": {
        "id": "vKxVOeZ4R6YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SRCを実装します．\n",
        "\n",
        "- [SRCの原著論文](https://ieeexplore.ieee.org/abstract/document/4483511)の[PDFファイル](http://www.columbia.edu/~jw2966/papers/WYGSM09-PAMI.pdf)\n",
        "- shapeが`(n, d)` の配列 `X` は，有効な画素数が `d` 個の訓練画像 `n` 枚を表します．\n",
        "- `fit(X,y)` は，訓練画像 `X` を正規化した配列 `A` を作ります．`A` のshapeは `(d, n)` です．各列の訓練画像のクラス番号は，shapeが `(n,)` の配列 `y` で与えられます．\n",
        "- `_predict` は，shapeが`(d,)`の質問画像 `b` に対してクラス番号を推論します．\n",
        "    - スパース解 `x_sp` の非ゼロ成分数の上限 `maxnnz` と，`b` をスパース回帰したときの相対誤差の下限 `tol` を指定できます．\n",
        "    - `maxnnz` を指定しない場合は，`d` の半分の値がデフォルトです．`tol` のデフォルトは0.01です．\n",
        "    - 再構成画像の有効な画素値 `A.dot(x_sp)` と `b` の相対誤差が `tol` 未満，または非ゼロ成分が `maxnnz` 以上になると，OMPは終了します．\n",
        "- `_compute_residual`は，各クラスの訓練画像と対応する回帰係数 `x_sp` で `b` を近似した残差（residual）を計算します．`_predict` は残差が最小のクラスを推論の結果とします．"
      ],
      "metadata": {
        "id": "Yn5bxBRY_b3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "class SRC:\n",
        "    def __init__(self, tol=1e-2):\n",
        "        self.tol = tol\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.A = normalize(X).T             # 正規化した訓練データ X を列にもつ行列 A \n",
        "        self.y_train = y                    # 各列の訓練データのクラス番号\n",
        "        self.classes_ = np.unique(y)        # クラス番号の全体集合\n",
        "\n",
        "    def predict(self, X, tol=None, maxnnz=None):\n",
        "        y_pred = [self._predict(b, tol, maxnnz)[0] for b in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    # 目的変数（質問画像）b のクラス番号を推論します．\n",
        "    def _predict(self, b, tol=None, maxnnz=None):\n",
        "        if tol is None: tol = self.tol\n",
        "        x_sp = OMP(self.A, b, delta=linalg.norm(b)*tol, maxnnz=maxnnz)\n",
        "        residual = self._compute_residual(x_sp, b)\n",
        "        # 残差 residual が最小のクラス番号を返します．\n",
        "        return self.classes_[np.argmin(residual)], residual, x_sp\n",
        "\n",
        "    # スパース解 x_sp に基づき，各クラスの訓練データのみで\n",
        "    # 目的変数（質問画像）b の合成を試みた残差 residual を返します．\n",
        "    def _compute_residual(self, x_sp, b):\n",
        "        residual = np.zeros(len(self.classes_))\n",
        "        for i, cid in enumerate(self.classes_):\n",
        "            idx = self.y_train == cid\n",
        "            residual[i] = linalg.norm(b - self.A[:,idx].dot(x_sp[idx]))\n",
        "        return residual\n",
        "\n",
        "    def score(self, X, y, tol=None, maxnnz=None):\n",
        "        y_pred = self.predict(X, tol, maxnnz)\n",
        "        return (y == y_pred).sum() / len(y)"
      ],
      "metadata": {
        "id": "BGqIdoZaiz_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SRCで欠損顔画像を認識します．\n",
        "- `qid` で質問画像の番号を指定します．`b` は質問画像の有効な画素値のみを持つ配列です．\n",
        "- 左に質問画像，右に再構成画像が表示されます．欠損なしの訓練画像と回帰係数（スパース解）`x_sp` で再構成しているので，欠損を修復した質問画像が得られます．\n",
        "- 更に，回帰係数 `x_sp` と各クラスの残差 `residual` をプロットします．"
      ],
      "metadata": {
        "id": "n1uvdLL50vu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SRC()\n",
        "model.fit(X_in_train[:,p_obs], y=y_train)\n",
        "\n",
        "qid = 9\n",
        "b = X_in_q[qid, p_obs]\n",
        "y_pred, residual, x_sp = model._predict(b, tol=1e-1, maxnnz=40)\n",
        "\n",
        "print(\"Ground truth:\", y_q[qid], \", Predicted:\", y_pred)\n",
        "print(\"Left: query, Right: sparse reconstruction\")\n",
        "imshows(np.c_[X_in_q[qid,:], normalize(X_train).T.dot(x_sp)].T, subplots=(1,2)); plt.show()\n",
        "\n",
        "plt.plot(x_sp, label=\"nnz=\"+str(np.count_nonzero(x_sp))); plt.legend(); plt.show()\n",
        "plt.bar(model.classes_, residual)"
      ],
      "metadata": {
        "id": "LMZWqIro05eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### すべての質問画像をSRCで認識します．\n",
        "- 数十秒～数分の時間がかかるので注意してください．\n",
        "- `tol` や `maxnnz` を変えて結果を観察してください．"
      ],
      "metadata": {
        "id": "gZpT6YklXfNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SRC()\n",
        "model.fit(X_in_train[:,p_obs], y=y_train)\n",
        "\n",
        "maxnnz = 40  # try 5, 10, 20, 30, 40, 50, 60\n",
        "tol = 0.1   # try 0.01, etc.\n",
        "from time import time\n",
        "\n",
        "print(\"Predicting labels (val) ..\", end=\"\")\n",
        "\n",
        "t0 = time()\n",
        "y_pred = model.predict(X_q[:,p_obs], maxnnz=maxnnz, tol=tol)\n",
        "\n",
        "print('.. done in %.2fs.' % (time() - t0))\n",
        "\n",
        "matches = (y_pred == y_q)\n",
        "print(\"Accuracy = %d / %d = %2.1f%%\" % (matches.sum(), len(matches), 100*matches.sum()/float(len(matches))))"
      ],
      "metadata": {
        "id": "okXZImCAtLem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 混同行列を表示します．\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "# Make predictions on test data\n",
        "cm = metrics.confusion_matrix(y_q, y_pred)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(20,16))\n",
        "sns.set(font_scale=0.75)\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", linewidths=0, square=True, cmap='Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r33CJO7_wHBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "wpoiS2jl7iJU"
      }
    }
  ]
}