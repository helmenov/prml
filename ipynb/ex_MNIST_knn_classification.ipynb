{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/prml/blob/master/ipynb/ex_MNIST_knn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UTNIg2oEn2n8"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST手書き数字画像のk近傍識別（k-NN）\n",
        "$k$-nearest neighbors classification ($k$-NN) of the MNIST digits\n",
        "\n",
        "----\n",
        "\n",
        "氏名：\n",
        "\n",
        "学生番号：\n",
        "\n",
        "----\n",
        "## 基本課題（必須）\n",
        "\n",
        "    1. 訓練データ数が100のときのk-NNの正答率（accuracy）と，\n",
        "       起こりやすい誤識別を報告してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    2. 訓練データ数が小さいとき，どのような正答率の改善策が考えられますか．\n",
        "       実際に改善の効果はどうでしたか．その理由も考察してください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    3. 訓練データ数を増やす利点と欠点をそれぞれ定量的に述べてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "    4.その他，気づいたこと，調べたことを書いてください．\n",
        "\n",
        "（ここに回答を書いてください）\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "発展課題（任意）がこのノートブックの後半にあります．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "mnist = pd.read_csv('/content/sample_data/mnist_test.csv', header=None) # 10k images\n",
        "#mnist = pd.read_csv('https://github.com/tsakailab/prml/raw/master/datasets/mnist_test.csv', header=None) # 10k images\n",
        "#mnist = pd.read_csv('https://pjreddie.com/media/files/mnist_train.csv', header=None) # 60k images\n",
        "\n",
        "y_all = mnist.iloc[:,0].to_numpy()\n",
        "Ximages_all = mnist.drop(columns=0).to_numpy().reshape(-1,28,28)\n",
        "\n",
        "# simulate noisy images\n",
        "#Ximages_all = Ximages_all + np.random.rand(*Ximages_all.shape) * 200\n",
        "#Ximages_all[Ximages_all > 255] = 255\n",
        "\n",
        "\n",
        "from skimage.filters import gaussian\n",
        "from skimage.exposure import equalize_hist as eh\n",
        "from skimage.transform import resize\n",
        "\n",
        "'''\n",
        "* blurring (https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian)\n",
        "* histogram equalization (https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html)\n",
        "* resize images (https://scikit-image.org/docs/stable/auto_examples/transform/plot_rescale.html)\n",
        "'''\n",
        "#Ximages_all = gaussian(np.float32(Ximages_all.transpose((1,2,0))), sigma=1.0, multichannel=True).transpose(2,0,1)\n",
        "#Ximages_all = eh(Ximages_all.transpose((1,2,0))).transpose(2,0,1) * 255\n",
        "#height, width = 8, 8; Ximages_all = resize(Ximages_all.transpose((1,2,0)), (height, width)).transpose(2,0,1)\n",
        "\n",
        "Ximages_all = np.uint8(Ximages_all)\n",
        "print(Ximages_all.dtype, \", max. pixel value = \", Ximages_all.max())\n",
        "print(\"(#images, height, width)\", Ximages_all.shape)"
      ],
      "metadata": {
        "id": "wxYrg4x3Ub5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7Ib1PU2n2oK",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title 画像を例示します\n",
        "#@title Show images of digits\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"%d images in total\" % len(y_all))\n",
        "\n",
        "# show the digits\n",
        "def plotMNIST(imgs, gts, preds=None, num=8, figsize=(6,6)):\n",
        "    fig = plt.figure(figsize=figsize)  # figure size in inches\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "    for i in range(num*num):\n",
        "        ax = fig.add_subplot(num, num, i + 1, xticks=[], yticks=[])\n",
        "        ax.imshow(imgs[i], cmap=plt.cm.gray, interpolation='nearest')\n",
        "\n",
        "        # label the image with the target value\n",
        "        ax.text(0, imgs.shape[1]*0.2, str(gts[i]), color='white')\n",
        "        if preds is not None:\n",
        "            if preds[i] == gts[i]:\n",
        "                ax.text(imgs.shape[2]*0.8, imgs.shape[1]*0.2, str(preds[i]), color='#a0ffa0')\n",
        "            else:\n",
        "                ax.text(imgs.shape[2]*0.8, imgs.shape[1]*0.2, str(preds[i]), color='red')\n",
        "\n",
        "\n",
        "p = np.random.randint(0, len(y_all), 8*8)\n",
        "plotMNIST(Ximages_all[p], y_all[p], num=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQFrBwjAn2oS"
      },
      "cell_type": "markdown",
      "source": [
        "### 実行と評価\n",
        "\n",
        "#### 設定値\n",
        "- `train_size`: 訓練データ（プロトタイプ）の数\n",
        "- `k`: 識別の参考にする近傍の訓練データ数"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "train_size = 100\n",
        "k = 1   # try k = 1, 3, 7, 15, 31, ...\n",
        "\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
        "#clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric='cosine')\n",
        "\n",
        "val_size = 1000"
      ],
      "metadata": {
        "id": "arAOq-4QlcA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 識別の実行と結果の例示\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "# split the data into training and validation sets\n",
        "Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages_all, y_all, \n",
        "                                                              train_size=train_size, test_size=val_size)\n",
        "\n",
        "# NumPy array of shape (#data, #pixels) for k-NN \n",
        "X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1))\n",
        "X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1))\n",
        "\n",
        "# let clf prepare the inference\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# predict the labels of the test data\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "# show examples of the prediction\n",
        "p = np.random.randint(0, len(y_val), 8*8)\n",
        "plotMNIST(Ximages_val[p], y_val[p], y_pred[p], num=8)\n",
        "\n",
        "# the number of correct matches / the total number of data points\n",
        "matches = (y_pred == y_val)\n",
        "print(\"Accuracy = %d / %d = %2.1f%%\" % (matches.sum(), len(matches), 100*matches.sum()/float(len(matches))))"
      ],
      "metadata": {
        "id": "K9nCZ5D6groz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgIqtl7Yn2oU",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title 反復試行による性能評価（時間がかかります）\n",
        "\n",
        "# NumPy array of shape (#data, #pixels) for k-NN \n",
        "X_all = np.reshape(Ximages_all, (Ximages_all.shape[0],-1))\n",
        "\n",
        "ntry = 100\n",
        "accuracy = np.zeros(ntry)\n",
        "for i in range(ntry):\n",
        "    # split the data into training and validation sets\n",
        "    Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages_all, y_all, \n",
        "                                                                  train_size=train_size, test_size=val_size)\n",
        "\n",
        "    # NumPy array of shape (#data, #pixels) for k-NN \n",
        "    X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1))\n",
        "    X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1))\n",
        "\n",
        "    # let clf prepare the inference\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # predict the labels of the test data\n",
        "    y_pred = clf.predict(X_val)\n",
        "\n",
        "    # the number of correct matches / the total number of data points\n",
        "    accuracy[i] = (y_pred == y_val).sum() / len(y_pred)\n",
        "\n",
        "print(u\"Accuracy = %2.1f\\u00B1%2.1f%% [%2.1f%%, %2.1f%%]\" \n",
        "      % (accuracy.mean()*100, accuracy.std()*100, accuracy.min()*100, accuracy.max()*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRUeztQpn2op",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title 混同行列（行：正解，列：予測）\n",
        "from sklearn import metrics\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "\n",
        "cm = metrics.confusion_matrix(y_val, y_pred)\n",
        "print(cm)\n",
        "\n",
        "#print(cm.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "h4Xq7nKCMeqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 発展課題\n",
        "\n",
        "k-NN をクラスで自作しましょう．[sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) に似た仕様とします．\n",
        "\n",
        "例えば，訓練データ `X_train` とクラスラベル `y_train` から最近傍法で `X_val` のクラスラベルの予測 `y_pred` を得るには\n",
        "```\n",
        "    k = 1\n",
        "    myclf = kNN(k)\n",
        "    myclf.fit(X_train, y_train)\n",
        "    y_pred = myclf.predict(X_val)\n",
        "```\n",
        "のように使うことを想定します．\n",
        "MNISTで訓練データが1000個の場合，`X_train` と `y_train` はそれぞれ shape が (1000,784) と (1000,) のNumPy配列です．"
      ],
      "metadata": {
        "id": "qFMWVuCjsNG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
        "\n",
        "# x1 と x2 の間の距離を返す関数\n",
        "def distance(x1, x2):\n",
        "    return np.sqrt(np.sum((np.float32(x1) - np.float32(x2))**2))\n",
        "\n",
        "# 自作の k-NN をクラスで定義しましょう．\n",
        "class kNN:\n",
        "\n",
        "    # 初期化の関数です．\n",
        "    # myclf = kNN(k) のように引数で与えられた k を self.k に記憶しておきます． \n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    # myclf.fit(X, y) のように訓練データ X と 正解ラベル y が与えられます．\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    # myclf.predict(X) とすると，Xの各行のデータを識別した結果を返します．\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # compute distances between x and all training data\n",
        "        # hint: distance(), self.X_train\n",
        "        distances = ######## your code here ########\n",
        "\n",
        "        # sort by distance and return indices of the first k neighbors\n",
        "        # hint: argsort(), distances, self.k\n",
        "        k_idx = ######## your code here ########\n",
        "\n",
        "        # extract the labels of the k nearest neighbor training samples\n",
        "        # hint: self.y_train, k_index\n",
        "        k_neighbor_labels = ######## your code here ########\n",
        "\n",
        "        # return the most common class label\n",
        "        pred = Counter(k_neighbor_labels).most_common(1)[0][0]\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "ySO1HTYEwqOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 自作の k-NN 識別器 myclf を生成する．\n",
        "# instanciate my own kNN classifier\n",
        "myclf = kNN(k)\n",
        "\n",
        "# 以下，変更は不要です．\n",
        "# no need to modify the following lines\n",
        "\n",
        "# split the data into training and validation sets\n",
        "Ximages_train, Ximages_val, y_train, y_val = train_test_split(Ximages_all, y_all, \n",
        "                                                              train_size=train_size, test_size=val_size)\n",
        "\n",
        "# NumPy array of shape (#data, #pixels) for k-NN \n",
        "X_train = np.reshape(Ximages_train, (Ximages_train.shape[0], -1))\n",
        "X_val = np.reshape(Ximages_val, (Ximages_val.shape[0], -1))\n",
        "\n",
        "# let clf prepare the inference\n",
        "myclf.fit(X_train, y_train)\n",
        "\n",
        "# predict the labels of the test data\n",
        "y_pred = myclf.predict(X_val)\n",
        "\n",
        "# show examples of the prediction\n",
        "p = np.random.randint(0, len(y_val), 8*8)\n",
        "plotMNIST(Ximages_val[p], y_val[p], y_pred[p], num=8)\n",
        "\n",
        "# the number of correct matches / the total number of data points\n",
        "matches = (y_pred == y_val)\n",
        "print(\"Accuracy = %d / %d = %2.1f%%\" % (matches.sum(), len(matches), 100*matches.sum()/float(len(matches))))"
      ],
      "metadata": {
        "id": "64N_WITlw8yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "お疲れさまでした．"
      ],
      "metadata": {
        "id": "-svKKyHE-Vcl"
      }
    }
  ]
}